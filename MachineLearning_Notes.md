[TOC]



### **Chap1. Feature Engineering**

对于机器学习，数据和特征决定了结果的上限，模型、算法的选择及优化则是在逐步接近这个上限。

特征工程本质：去除原始数据中的杂质和冗余，设计更高效的特征以描述问题与预测模型间的关系。

2种数据：

​	结构化数据：关系数据库中的表。

​	非结构化数据：文本，图像，音频，视频。

#### **01 特征归一化 Normalization**

消除数据特征间的量纲，对特征进行归一化处理，使不同指标间有可比性。

**❀特征归一化**

#### Q: 为什么需要对数值型的特征做归一化?

A: 可以将所有的特征都统一到一个大致相同的数值区间内。

比如有两个数值型特征，X1∈[0,10]，X2∈[0,3]。采用随机梯度下降，不归一化的情况下，在学习率相同时，X1的更新速度会大于X2，需要多次迭代才能找到最优解。使用归一化，X1和X2的的更新速度变为更一致，容易更快地通过梯度下降找到最优解。

常用的方法有：

​	(1) 线性函数归一化 Min-Max Scaling: 对原始数据进行线性变换，使结果映射到[0,1]范围，算一种等比缩放。
$$
Xnorm = \frac{X - Xmin}{Xmax - Xmin}
$$
​	(2) 零均值归一化 Z-Score Normalization: 将原始数据映射到均值=0，标准差=1的分布上。
$$
z = \frac{x-\mu }{\sigma }
$$
注：一般通过梯度下降求解的模型通常需要归一化，包括线性回归，逻辑回归，SVM，神经网络等模型。但是，决策树模型并不适用，C4.5: 决策树在进行节点分裂时主要依据数据集关于特征的信息增益比，信息增益比跟特征是否经过归一化是无关的。





#### **02 类别型特征 Categorical Feature**

通常指在优先选项内取值的特征，性别，血型等。类别型特征的原始输入通常是字符串形式，除了决策树等少数模型可以直接处理字符串形式的输入，对于逻辑回归，SVM等模型，必须先将类别型特征转换成数值型特征才可。

**❀序号编码 Ordinal Encoding，独热编码 One-hot Encoding， 二进制编码 Binary Encoding**

#### Q: 在对数据预处理时，该怎样处理类别型特征?

A: 序号编码: 通常用于处理具有大小关系且排序的数据。成绩，高-3，中-2，低-1。

​    独热编码: 处理类别间不具有大小关系的特征。血型，A-(1,0,0,0)，B-(0,1,0,0)，C-(0,0,1,0)，D-(0,0,0,1)。注：当类别取值较多的情况下，(1) 使用稀疏向量来节省空间。目前大多数算法均支持稀疏向量形式的输入。(2) 配合特征选择来降低纬度。高维度特征一般存在的问题有: K-近邻，高维空间两点间的距离很难有效衡量；逻辑回归模型，参数的数量随维度的增高而增加，容易过拟合；一般只有部分维度是对分类、预测有帮助的。

​    二进制编码: 先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。**本质**是利用二进制对ID进行哈希映射，得到0/1特征向量，维度少于独热编码，节省存储空间。





#### **03 高维组合特征**

**❀组合特征**

#### Q: 什么是组合特征？如何处理高维组合特征？

A: 为了提高复杂关系的拟合能力，特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。以广告点击预估问题为例，原始数据有语言和类型两种离散特征。可以将语言和类型组成二阶特征。





#### **04 组合特征**

面对多种高维特征，如果只简单地两两组合，依然容易存在参数过多，过拟合的问题，且并非所有的特征组合都是有意义的。

**❀组合特征**

#### Q: 怎样有效地找到组合特征？





#### **05 文本表示模型**

**❀词袋模型 Bag of Words，TF-IDF Term Frequency-Inverse Document Frequency，主题模型 Topic Model，词嵌入模型 Word Embedding**

#### Q: 有哪些文本表示模型？有什么优缺点？

A: **词袋模型和N-gram模型**: 词袋模型是最基础的文本表示模型。每篇文章看成一袋子词，忽略每个词出现的顺序。文章可以表示为一个长向量，向量中的每一个维度代表一个单词，该维度对应的权重反映了这个词在原文中的重要程度。用TF-IDF来计算权重
$$
TF-IDF(t,d) = TF(t,d)×IDF(t)
$$
 TF(t,d)为单词t在文档d中出现的频率，IDF(t)是逆文档频率，用来衡量单词t对表达语义所起的重要性，
$$
IDF(t) = log\frac{文章总数 }{包含t的文章总数+1}
$$
若一个单词在很多的文章里都出现，那么它可能是个通用词汇，对于区分某篇文章特殊语义贡献较小，重要性就会被削弱。

但是，将文章按照单词划分也不是很好的办法。拆分后的单个词与原来连续的词含义差别很大。通常，可以将连续出现的n个词组成的词组作为一个单的的特征放到向量表示中去，即N-gram模型。

​     **主题模型**: 从文本库中发现有代表性的主题(得到每个主题上面词的分布特性)，且能够计算出每篇文章的主题分布。

​    **词嵌入与深度学习模型**: 词嵌入是一类将词向量化的模型统称。主要是将每个词都映射成低维空间K(K=50~300)上的一个dense vector。K中每一维空间可看做是一个隐含的主题。

**注**: 在传统的浅层机器学习模型中，一个好的特征工程可以带来算法效果的提升。而深度学习模型为我们提供了一种自动地进行特征工程的方式，模型中的每个隐层都可以认为对应着不同抽象层次的特征。**卷积和循环神经网络**在文本表示中取得了很好的效果，主要是由于它们能够更好地对文本进行建模，抽取一些高层的语义特征。**与全连接的网络结构**相比，卷积和循环神经网络一方面抓住了文本的特性，另一方面减少了网络中待学习的参数，提高训练速度，降低过拟合的风险。





#### **06 Word2Vec**

由Google提出的一种常用的词嵌入模型之一。Word2Vec实际是一种浅层神经网络模型，有两种网络结构: CBOW Continues Bag of Words和 Skip-gram。

**❀Word2Vec，隐狄利克雷模型LDA，CBOW，Skip-gram**

#### Q: Word2Vec如何工作？它和LDA有什么区别与联系？

A: CBOW是根据上下文出现的词语来预测当前词的生成概率，

​    Skip-gram是根据当前词来预测上下文中各词的生成概率。

​    CBOW，Skip-gram都可以表示成由输入层，映射层，输出层组成的神经网络。

​    LDA是利用文档中单词的共现关系来对单词按主题聚类，即对文档-单词矩阵进行分解，得到文档-主题和主题-单词两个概率分布。Word2Vec是对上下文-单词矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地融入了上下文共现的特征。若2个单词对应的Word2Vec向量相似度高，那么他们很可能经常在同样的上下文中出现。

  主题模型和词嵌入模型两类的区别在于模型本身，主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，包括需要推测的隐含变量(主题)；词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的dense vector。





#### **07 图像数据不足时的处理**

**❀迁移学习，GAN，图像处理，上采样，数据扩充**

#### Q: 图像分类任务中，训练数据不足会带来什么问题？如何缓解数据不足的问题？

A: 主要问题是过拟合，在测试集上泛化效果不佳。处理方法：

​	(1) 基于模型，采用降低过拟合风险的措施，包括简化模型(非线性模型简化为线性)，添加约束以缩小假设空间(L1/L2正则)，集成学习，dropout超参数等。

​	(2) 基于数据，通过先验知识，在保持特定信息的前提下，用数据扩充。一定程度内的随机旋转，平移，缩放，剪裁，翻转等。这些变换对应同一个目标在不同角度的观察结果。也可以在像素中增加噪声，椒盐噪声，高斯白噪声等。颜色变换，改变亮度，清晰度，对比度，锐度等。

​	(3) 对图像进行特征提取，在图像的特征空间进行变换，利用数据扩充或者上采样。

​	(4) 使用生成模型来合成一些新样本，GAN。

​	(5) 迁移学习：借用一个在大规模数据集上训练好的通用模型，并在针对目标任务的小数集上fine-tune。





























### **Chap2 模型评估**

#### **01 评估指标的局限性**

**❀准确率 Accuracy，精确率 Precision，召回率 Recall，均方根误差 Root Mean Square Error**

#### Q: 准确率的局限性。

A: 准确率是**分类正确的样本**占**总样本个数**的比例。它是分类问题中最简单也是最直观的评价指标，但是存在明显缺陷。当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。如：当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。

#### Q: 精确率与召回率的权衡。

A: 精确率是**分类正确的正样本个数**占**分类器判定为正样本的样本个数**的比例。（预测为正的样本中有多少是真正的正样本。）
$$
P = \frac{TP}{TP+FP}
$$
​    召回率是**分类正确的正样本个数**占**真正的正样本个数**的比例。（样本中的正例有多少被预测正确了）
$$
R = \frac{TP}{TP+FN}
$$
*一个分母是预测为正的样本数，另一个是原来样本中所有的正样本数。



在排序问题中，一般没有确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N返回结果的Precision和Recall来衡量排序模型的性能，认为模型返回的Top N的结果就是模型判定的正样本，计算前N个位置上的Precision和前N个位置上的Recall。

Precision和Recall既矛盾有统一，为了提高Precision，分类器需要尽量在更有把握时才把样本预测为正样本，但此时会因为过于保守而漏掉很多没有把握的正样本，导致Recall降低。

为了综合评估一个排序模型的好坏，不仅要看在不同Top N下的Precision和Recall，也要绘制出模型的P-R曲线。

**P-R曲线**：横轴召回率，纵轴精确率。对于一个排序模型，P-R曲线上的一个点表示，在某一阈值下，模型将大于该阈值的结果判定为正样本，小于改阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。整条P-R曲线是通过将阈值从高到低移动而生成的。

**F1-Score**是精确率和召回率的调和平均值，我们使用调和平均而不是简单的算术平均的原因是：调和平均可以惩罚极端情况。一个具有 1.0 的精度，而召回率为 0 的分类器，这两个指标的算术平均是 0.5，但是 F1 score 会是 0。
$$
F1 = \frac{2×precision×recall }{precision+recall}
$$

#### Q: 平方根误差的意外。

A: 第i个样本点的真实值-第i个样本点的预测值，一共n个样本点。
$$
RMSE =\sqrt{\frac{\sum_{i=1}^{n}(y_{i}-y'_{i})^{2}}{n}}
$$
一般，RMSE能很好地反映回归模型预测值与真实值的偏离程度。但是，若存在个别偏离程度非常大的离群点时，即使离群点数量非常少，也会让RMSE指标变得很差。解决方法：(1)如果认为离群点是噪声点，就在数据预处理的时候把噪声过滤掉。(2)如果不认为是噪声，需要进一步提高模型预测能力，将离群点产生的机制建模进去。(3)找一个更合适的指标来评估模型。平均绝对百分比误差MAPE的鲁棒性比RMSE更好，Mean Absolute Percent Error，MPAE把每个点的误差进行归一化，降低了个别离群点带来的绝对误差的影响。
$$
MPAE=\sum_{i=1}^{n}\left | \frac{y_{i}-y'_{i}}{y_{i}} \right | × \frac{100}{n}
$$


#### **02 ROC曲线**

ROC曲线一般用于评估二值分类器。

**❀ROC曲线，曲线下的面积AUC (Aera Under Curve)，P-R曲线**

#### Q: 什么是ROC曲线？

A: Receiver Operating Characteristic Curve的简称。

横坐标FPR，假阳性；纵坐标为TPR，真阳性。FPR=FP/N，TPR=TP/P。（Recall=TPR）

P是真实的正样本个数，N是真实的负样本个数。TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被分类器预测为正样本的个数。

#### Q: 如何绘制ROC曲线？

A: ROC曲线是通过不断移动分类器的**截断点**来生成曲线上的一组关键点的。截断点指区分正负预测结果的阈值。从最高得分开始，逐渐调整到最低得分，每一个截断点都会对应生成一个FPR和TPR，在ROC图上连接所有的点就得到最终的ROC曲线。

#### Q: 如何计算AUC?

A: AUC就是ROC曲线下的面积大小，可以量化地反映基于ROC曲线衡量出的模型性能。沿着ROC轴做积分就可以了。由于ROC曲线一般处于y=x上方，所以AUC的取值一般在0.5~1间。AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。

#### Q: ROC曲线比P-R曲线有何特点？

A: 当正负样本的分布发生变化时，ROC曲线的形状基本保持不变，P-R曲线的形状一般会发生剧烈的变化。ROC曲线因此能够尽量降低不同测试集带来的干扰，更客观地衡量模型的性能。因为实际情况下，正负样本数量不均衡。选择的测试集不同，P-R曲线的变化就会非常大，ROC曲线能够更稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多。如果想看到模型在特定数据集的表现，P-R曲线更直观。



#### **03 余弦距离**

评估样本距离：分析两个特征向量间的相似性时，常用余弦相似度来表示，范围[-1,1]。余弦距离就是1-余弦相似度，范围[0,2]。

**❀余弦相似度，余弦距离，欧氏距离，距离的定义**

#### Q: 在什么场景使用余弦相似度而不是欧氏距离？

A: 余弦相似度定义为，cos(A,B) = A·B /|A||B|，关注的是向量间的角度关系，不关心他们的绝对大小，其取值范围是[-1,1]。(1)当一对文本相似度的长度差距很大、但是内容相近时，若使用词频或词向量作为特征，他们在特征空间中的欧氏距离通常很大；使用余弦相似度的话，夹角可能很小，因而相似度高。(2)在文本、图像、视频等领域，研究对象的特征维度往往很高，余弦相似度依然可以保持，相同=1，相交=0，相反=-1的性质，欧氏距离的数值会受到维度的影响。

在word2vec中，向量的模长经过归一化，欧式距离和余弦距离有单调关系。若选择距离小的近邻，最终两者选择的结果是相同的。
$$
\left \| A-B \right \|_{2} = \sqrt{2(1-cos(A,B))}
$$
欧氏距离体现数值上的绝对差异，余弦距离体现方向上的相对差异。

如：我们统计两部剧的用户观看行为，用户A的观看向量为(0,1)，用户B为(1,0)，二者的余弦距离很大，欧氏距离很小，我们分析两个用户对不同视频的偏好，更关注相对差异，应使用**余弦距离**。

我们分析用户活跃度，以登陆次数和平均观看时长作为特征时，余弦距离会认为(1,10)和(10,100)两个用户很近，但是显然这两个用户的活跃度有很大差异，此时更应该关注**欧氏距离**的绝对差异。

#### Q: 余弦距离是否是一个严格定义的距离？

A: 不是严格定义的距离，因为余弦距离满足 正定性，对称性，不满足三角不等式。







#### **04 A/B测试**

**❀A/B测试，实验组，对照组**

#### Q: 在对模型进行过充分的离线评估后，为什么还要进行在线A/B测试？

A: (1)离线评估没办法完全消除模型过拟合的影响，离线评估的结果无法完全替代线上评估的结果。(2)离线评估无法完全还原线上的工程环境，延迟、数据丢失、标签数据缺失等情况。(3)线上系统的某些商业指标无法在离线评估中计算，用户点击率，留存时长等。这些还是需要由A/B测试进行全面评估。

#### Q: 如何进行线上A/B测试？

A: 进行用户分桶，分成实验组和对照组，实验组的用户用新模型，对照组用户旧模型。分桶过程中注意样本独立性和采样方式的无偏性，确保每个用户只能分到同一个桶里，分桶过程中的user_id是随机数才能保证桶中的样本是无偏的。

#### Q: 如何划分实验组和对照组？



#### **05 模型评估的方法**

划分样本和模型验证的过程中，是存在不同的抽样方法和验证方法。

**❀Holdout验证，交叉验证，自助法，微积分**

#### Q: 模型评估有哪些主要的验证方法，优缺点是什么？

A: **Holdout检验**：最简单最直接的验证方法。将原始样本随机化氛围训练集合验证集。缺点很明显。在验证集上计算出来的最后评估指标与原始分组有很大关系。

   **k-fold交叉验证**：全部样本划分为k个大小相等的样本子集，依次遍历k个子集，每次把当前子集作为验证集，其余为训练集，进行训练和评估。最后把k次评估指标的平均值作为最终的评估指标，一般k=10。

如果样本数据本来就很少，再划分就会影响模型训练效果。  

  **自助法**：基于自助采样，对于总数为n的样本集合，进行n次有放回地随机抽样，得到大小为n的训练集。n次采样中，有的样本会重复采样，有的样本没有被抽出过，将没有选择过的样本作为验证集。

#### Q: 在自助采样中，对n个样本进行n次自助采样，当n趋于无穷大时，最终有多少数据从未被选择过？

36.8%









#### **06 超参数调优**

#### Q: 有哪些超参数调优方法？

A: 网格搜索，随机搜索，贝叶斯优化等算法。超参数搜索算法包括：目标函数，即算法需要最大化最小化的目标；搜索范围，通过上限和下限来确定；其他参数，搜索步长等。

网格搜索：最简单应用最广泛，查找搜索范围内的所有点来确定最优值。采用较大的搜索范围以及较小的步长，很有可能找到全局最优，但是十分消耗计算资源和时间。因此，网格搜索一般会先使用较广的搜索范围和较大的步长，来寻找全局最优的可能位置；然后缩小搜索范围和步长，找到更精确的最优。

随机搜索：不再测试上界和下界间的所有值，在搜索范围中随机选取样本点。理论依据是：如果样本点集足够大，随机采样也能找到全局最优。

贝叶斯优化：充分利用之前的搜索结果，通过对目标函数形状进行学习，找到使目标函数向全局最优提升的参数。先根据先验分布假设一个搜集函数；每次使用新的采样点来检测目标函数时，利用这个信息来更新目标函数的先验分布；算法测试由后验分布给出的全局最值最可能出现的位置的点。注意，一旦找到了一个局部最优，它会在该区域不断采样，很容易陷入局部最优。故贝叶斯优化会在探索（在未取样的区域获取采样点）和利用（根据后验分布在最可能出现全局最优的区域进行采样）之间找到一个平衡。



#### **07 过拟合与欠拟合**

**❀过拟合，欠拟合**

#### Q: 过拟合和欠拟合具体指什么现象？

A: 过拟合：模型在训练集表现很好，在测试集和新数据上表现较差。

​     欠拟合：模型在训练和预测时表现都不好。

#### Q: 说出几种降低过拟合和欠拟合的方法？

A: 降低过拟合：

​    (1)获取更多的训练数据。最有效的方法，更多的样本可以让模型学习到更有效的特征，减少噪声。直接增加实验数据一般很难，通过一定规则来扩充数据。

​    (2)降低模型复杂度。神经网络模型中减少网络层数、神经元个数。在决策树模型中降低树的深度、剪枝。

​    (3)正则化方法。给模型参数加上正则约束，将权值的大小加入到损失函数中。

​    (4)集成学习。把多个模型组合在一起，降低单一模型的过拟合风险。

   降低欠拟合：

​    (1)添加新特征。梯度提升决策树，deep-crossing等。

​    (2)增加模型复杂度。线性模型增加高次项，神经网络中增加网络层数或神经元个数。

​    (3)减小正则化系数。











### Chap13 GAN

**❀MiniMax游戏，值函数，JS距离 Jensen-Shannon，概率生成模型，优化饱和**

#### **01 初始GANs**

#### Q: 简述GANs的基本思想和训练过程。

A: GAN的主要框架包括生成器Generator和判别器Discriminator两个部分。

生成器用于合成”假“样本，判别器用于判断输入的样本是真实的还是合成的。

生成器从先验分布中得到随机信号，经过神经网络的变换，得到模拟样本；判别器及接受来自生成器的模拟样本也接收来自实际数据集的真实样本，自己判断样本来源。二者置身于对抗环境中，生成器尽可能造出样本迷惑判别器，判别器尽可能识别出来自生成器的样本。对抗不是目的，在对抗中让双方能力各有所长才是目的，理想情况下，生成器和判别器最终达到平衡。

GAN采用对抗策略进行模型训练，生成器通过调节自身参数，使得其生产的样本尽量难以被判别器识别出是真实样本还是模拟样本；判别器通过调节自身参数，使得能尽可能准确地判断出输入样本的来源。具体训练时，采用生成器和判别器交替优化的方式。

(1) 训练判别器时，先固定生成器G；然后利用生成器随机模拟产生样本G(z)作为负样本(z是一个随机变量)，并从真实数据集中采样获得正样本X；把正负样本输入到判别器D中，根据判别器的输出<u>D(X)或D(G(z))</u>和样本标签来计算误差；利用误差反向传播算法更新判别器D的参数。

(2) 训练生成器时，先固定判别器D；然后利用当前生成器G随机模拟产生样本G(z)，并输入到判别器D中；根据判别器的输出D(G(z))和样本标签来计算误差，最后利用误差反向传播算法来更新生成器G的参数。

#### Q: GANs的值函数。

A: 判别器D试图识别实际数据为真实样本，识别生成器生成的数据为模拟样本，即一个二分类的问题，损失函数是negative log-likelihood，也称Categorical Cross-Entropy Loss，
$$
L(D) =-\int p(x)[p(data|x)logD(x)+p(g|x)log(1-D(x)]dx
$$
D(x)表示判别器预测x为真实样本的概率，p(data|x)和p(g|x) 表示x分属数据集和生成器两类的概率。样本x的来源p(data)=p(g)=0.5。
$$
p_{data}(x)\doteq p(x|data)
$$

$$
p_{g}(x)\doteq p(x|g)
$$

分别为从实际数据集得到x的概率，从生成器得到x的概率，x的总概率有：
$$
p(x) = p_{src}(data)p(x|data)+ p_{scr}(g)p(x|g)
$$
最终的目标函数为
$$
L(D) =-\frac{1}{2}(E_{x\sim p_{data}(x)}[logD(x)]+E_{x\sim p_{g}(x)}[log(1-D(x))])
$$
值函数为：
$$
V(G,D) =E_{x\sim p_{data}(x)}[logD(x)]+E_{x\sim p_{g}(x)}[log(1-D(x))]
$$
判别器D最大化值函数，生成器G最小化值函数，即min(G)max(D) V(G,D)。