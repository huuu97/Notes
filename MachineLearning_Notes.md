### Chap1. Feature Engineering

对于机器学习，数据和特征决定了结果的上限，模型、算法的选择及优化则是在逐步接近这个上限。

特征工程本质：去除原始数据中的杂质和冗余，设计更高效的特征以描述问题与预测模型间的关系。

2种数据：

​	结构化数据：关系数据库中的表。

​	非结构化数据：文本，图像，音频，视频。

#### **01 特征归一化 Normalization**

消除数据特征间的量纲，对特征进行归一化处理，使不同指标间有可比性。

**Q: 为什么需要对数值型的特征做归一化？**

A: 可以将所有的特征都统一到一个大致相同的数值区间内。

比如有两个数值型特征，X1∈[0,10]，X2∈[0,3]。采用随机梯度下降，不归一化的情况下，在学习率相同时，X1的更新速度会大于X2，需要多次迭代才能找到最优解。使用归一化，X1和X2的的更新速度变为更一致，容易更快地通过梯度下降找到最优解。

常用的方法有：

​	(1) 线性函数归一化 Min-Max Scaling: 对原始数据进行线性变换，使结果映射到[0,1]范围，算一种等比缩放。
$$
Xnorm = \frac{X - Xmin}{Xmax - Xmin}
$$
​	(2) 零均值归一化 Z-Score Normalization: 将原始数据映射到均值=0，标准差=1的分布上。
$$
z = \frac{x-\mu }{\sigma }
$$
注：一般通过梯度下降求解的模型通常需要归一化，包括线性回归，逻辑回归，SVM，神经网络等模型。但是，决策树模型并不适用，C4.5: 决策树在进行节点分裂时主要依据数据集关于特征的信息增益比，信息增益比跟特征是否经过归一化是无关的。